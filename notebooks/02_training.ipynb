{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bde6ab4",
   "metadata": {},
   "source": [
    "# Training the Multi-Modal Neural Network\n",
    "\n",
    "This notebook demonstrates how to configure and run training for the multi-modal neural network with double-loop learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fd9d7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2136b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from src.training.trainer import Trainer\n",
    "from src.utils.config import load_config\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516471a",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87667d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = '../configs/default.yaml'\n",
    "config = load_config(config_path)\n",
    "print(\"Configuration loaded:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec20010",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46550b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(config_path=config_path)\n",
    "print(\"Trainer initialized\")\n",
    "print(f\"Model device: {trainer.device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in trainer.model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45af7d8",
   "metadata": {},
   "source": [
    "## Verify Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before training\n",
    "print(f\"Train loader size: {len(trainer.train_loader)}\")\n",
    "print(f\"Number of batches: {len(trainer.train_loader.dataset)}\")\n",
    "\n",
    "# Test loading one batch\n",
    "try:\n",
    "    batch = next(iter(trainer.train_loader))\n",
    "    print(f\"Batch keys: {batch.keys()}\")\n",
    "    print(f\"Batch shapes: {[(k, v.shape) for k, v in batch.items() if isinstance(v, torch.Tensor)]}\")\n",
    "except StopIteration:\n",
    "    print(\"ERROR: Train loader is empty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3850d53",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718832dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training (this may take time depending on your hardware)\n",
    "# Uncomment the line below to start training\n",
    "# trainer.train()\n",
    "\n",
    "# For a quick test with limited epochs:\n",
    "print(\"To run training, set max_epochs in config and uncomment:\")\n",
    "print(\"  trainer.train()\")\n",
    "print(\"\\nCurrent training config:\")\n",
    "print(f\"  Max epochs: {trainer.config.get('training', {}).get('max_epochs', 'not set')}\")\n",
    "print(f\"  Batch size: {trainer.config.get('data', {}).get('batch_size', 'not set')}\")\n",
    "print(f\"  Learning rate: {trainer.config.get('training', {}).get('learning_rate', 'not set')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23610278",
   "metadata": {},
   "source": [
    "## Monitor Training Progress\n",
    "\n",
    "You can monitor training using TensorBoard or W&B (Weights & Biases) if configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aaec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training logs and outputs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('../outputs')\n",
    "checkpoint_dir = output_dir / 'checkpoints'\n",
    "log_dir = output_dir / 'logs'\n",
    "\n",
    "print(\"Training artifacts:\")\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob('*.pt'))\n",
    "    print(f\"\\n✓ Checkpoints ({len(checkpoints)}):\")\n",
    "    for ckpt in sorted(checkpoints)[-5:]:  # Show last 5\n",
    "        size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {ckpt.name} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\\n  No checkpoints yet\")\n",
    "\n",
    "if log_dir.exists():\n",
    "    logs = list(log_dir.glob('*.log'))\n",
    "    print(f\"\\n✓ Logs ({len(logs)}):\")\n",
    "    for log in sorted(logs)[-3:]:  # Show last 3\n",
    "        print(f\"  - {log.name}\")\n",
    "else:\n",
    "    print(\"\\n  No logs yet\")\n",
    "\n",
    "# Note about monitoring\n",
    "print(\"\\nTo monitor training in real-time:\")\n",
    "print(\"  - Check logs in: outputs/logs/\")\n",
    "print(\"  - View checkpoints in: outputs/checkpoints/\")\n",
    "if config.get('logging', {}).get('use_wandb', False):\n",
    "    print(\"  - W&B dashboard: https://wandb.ai/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
