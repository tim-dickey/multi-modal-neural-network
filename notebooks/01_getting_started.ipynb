{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2749439e",
   "metadata": {},
   "source": [
    "# Getting Started with Multi-Modal Neural Network\n",
    "\n",
    "This notebook provides a step-by-step guide to setting up the workspace for the multi-modal neural network project with double-loop learning and Wolfram Alpha integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f3f2d",
   "metadata": {},
   "source": [
    "## 1. Install Python and Pip\n",
    "\n",
    "First, ensure Python 3.10+ and pip are installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Check if pip is available\n",
    "try:\n",
    "    import pip\n",
    "    print(f\"Pip version: {pip.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Pip is not installed. Please install pip.\")\n",
    "    \n",
    "# Verify minimum Python version\n",
    "version_info = sys.version_info\n",
    "if version_info.major >= 3 and version_info.minor >= 10:\n",
    "    print(\"âœ“ Python version is compatible (3.10+)\")\n",
    "else:\n",
    "    print(\"âœ— Python 3.10 or higher is required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf33d1b",
   "metadata": {},
   "source": [
    "## 2. Create Virtual Environment\n",
    "\n",
    "Create a virtual environment to isolate project dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ffbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Virtual environment creation is typically done from the terminal\n",
    "# If running this in Jupyter, the environment is already active\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "\n",
    "if in_venv:\n",
    "    print(\"âœ“ Running in a virtual environment\")\n",
    "    print(f\"  Environment path: {sys.prefix}\")\n",
    "else:\n",
    "    print(\"Not in a virtual environment\")\n",
    "    print(\"Tip: Create and activate a venv with:\")\n",
    "    print(\"  python -m venv .venv\")\n",
    "    print(\"  .venv\\\\Scripts\\\\activate  (Windows)\")\n",
    "    print(\"  source .venv/bin/activate  (Linux/Mac)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa19ac",
   "metadata": {},
   "source": [
    "## 3. Activate Virtual Environment\n",
    "\n",
    "Activate the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78115eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate virtual environment (this may not work in notebook, do it in terminal)\n",
    "# In terminal: venv\\Scripts\\activate (Windows) or source venv/bin/activate (Linux/Mac)\n",
    "\n",
    "print(\"Please activate the virtual environment in your terminal before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3f343",
   "metadata": {},
   "source": [
    "## 4. Install Required Packages\n",
    "\n",
    "Install the project dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce06595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "print(\"Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8a98f",
   "metadata": {},
   "source": [
    "## 5. Set Up Project Directory\n",
    "\n",
    "The project directory structure is already created. Verify it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ad0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check project structure\n",
    "\n",
    "dirs = ['src', 'configs', 'notebooks', 'tests', 'docs', 'examples']\n",
    "for d in dirs:\n",
    "    if os.path.exists(f'../{d}'):\n",
    "        print(f\"âœ“ {d} directory exists\")\n",
    "    else:\n",
    "        print(f\"âœ— {d} directory missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e47afe",
   "metadata": {},
   "source": [
    "## 6. Configure Git Repository\n",
    "\n",
    "Initialize Git if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Git repository status\n",
    "from src.utils.subprocess_utils import _safe_subprocess_run\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Check if we're in a git repository\n",
    "    result = _safe_subprocess_run(['git', 'rev-parse', '--git-dir'], timeout=5, cwd='..')\n",
    "    if result and result.returncode == 0:\n",
    "        print(\"âœ“ Git repository initialized\")\n",
    "        \n",
    "        # Get current branch\n",
    "        branch_result = _safe_subprocess_run(['git', 'branch', '--show-current'], timeout=5, cwd='..')\n",
    "        if branch_result and branch_result.stdout.strip():\n",
    "            print(f\"  Current branch: {branch_result.stdout.strip()}\")\n",
    "        \n",
    "        # Check for uncommitted changes\n",
    "        status_result = _safe_subprocess_run(['git', 'status', '--short'], timeout=5, cwd='..')\n",
    "        if status_result and status_result.stdout.strip():\n",
    "            print(\"  Uncommitted changes detected\")\n",
    "        else:\n",
    "            print(\"  Working directory clean\")\n",
    "    else:\n",
    "        print(\"Git repository not initialized\")\n",
    "        print(\"Run: git init\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Git not found. Please install Git.\")\n",
    "\n",
    "# Check .gitignore\n",
    "gitignore_path = '../.gitignore'\n",
    "if os.path.exists(gitignore_path):\n",
    "    print(\"âœ“ .gitignore exists\")\n",
    "else:\n",
    "    print(\"âœ— .gitignore not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5376a1",
   "metadata": {},
   "source": [
    "## 7. Run Initial Tests\n",
    "\n",
    "Run a simple test to verify the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify key dependencies\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— PyTorch not installed\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"âœ“ Transformers version: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— Transformers not installed\")\n",
    "\n",
    "try:\n",
    "    from src.training.trainer import Trainer\n",
    "    from src.models.multi_modal_model import MultiModalModel\n",
    "    from src.data.dataset import MultiModalDataset\n",
    "    print(\"âœ“ Project modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Failed to import project modules: {e}\")\n",
    "\n",
    "print(\"\\nâœ“ Setup verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31620e",
   "metadata": {},
   "source": [
    "## 8. GPU Detection and Configuration\n",
    "\n",
    "Check if GPU is available and configure for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect GPU configuration\n",
    "from src.utils.gpu_utils import detect_gpu_info, print_gpu_info, check_mixed_precision_support\n",
    "\n",
    "# Get detailed GPU information\n",
    "gpu_info = detect_gpu_info()\n",
    "print_gpu_info(gpu_info)\n",
    "\n",
    "# Check mixed precision support\n",
    "print(\"\\nMixed Precision Training Support:\")\n",
    "mp_support = check_mixed_precision_support()\n",
    "print(f\"  FP16 (Half Precision): {'âœ… Supported' if mp_support['fp16'] else 'âŒ Not supported'}\")\n",
    "print(f\"  BF16 (BFloat16): {'âœ… Supported' if mp_support['bf16'] else 'âŒ Not supported'}\")\n",
    "print(f\"  TF32 (TensorFloat32): {'âœ… Supported' if mp_support['tf32'] else 'âŒ Not supported'}\")\n",
    "\n",
    "# Check for external GPUs\n",
    "if gpu_info.get('external_gpu_count', 0) > 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXTERNAL GPU DETECTED\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ðŸ”Œ Found {gpu_info['external_gpu_count']} external GPU(s)\")\n",
    "    for device in gpu_info['devices']:\n",
    "        if device.get('is_external', False):\n",
    "            print(f\"\\n  â€¢ {device['name']}\")\n",
    "            if device.get('connection_type'):\n",
    "                print(f\"    Connection: {device['connection_type']}\")\n",
    "            print(f\"    Memory: {device['total_memory_gb']:.2f} GB\")\n",
    "    print(\"\\nâš  Note: External GPUs may have 10-25% performance reduction\")\n",
    "    print(\"  due to Thunderbolt/USB bandwidth limitations.\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS FOR YOUR SYSTEM:\")\n",
    "print(\"=\"*70)\n",
    "if gpu_info['available']:\n",
    "    print(\"âœ… GPU training is available!\")\n",
    "    print(\"\\nRecommended config.yaml settings:\")\n",
    "    print(\"  hardware:\")\n",
    "    print(\"    device: 'auto'  # Will automatically use GPU\")\n",
    "    \n",
    "    if gpu_info['device_count'] > 1:\n",
    "        print(f\"\\nâœ… Multiple GPUs detected ({gpu_info['device_count']} GPUs)\")\n",
    "        print(\"  For multi-GPU training:\")\n",
    "        print(\"    device: 'cuda:0'  # Specify GPU ID\")\n",
    "        print(\"    ddp: true          # Enable Distributed Data Parallel\")\n",
    "    \n",
    "    # Mixed precision recommendations\n",
    "    if mp_support['bf16']:\n",
    "        print(\"\\n  âœ… BF16 mixed precision recommended (best for Ampere GPUs):\")\n",
    "        print(\"    training:\")\n",
    "        print(\"      mixed_precision: 'bf16'\")\n",
    "    elif mp_support['fp16']:\n",
    "        print(\"\\n  âœ… FP16 mixed precision recommended:\")\n",
    "        print(\"    training:\")\n",
    "        print(\"      mixed_precision: 'fp16'\")\n",
    "else:\n",
    "    print(\"âš  No GPU detected - training will use CPU\")\n",
    "    print(\"\\nTo enable GPU training:\")\n",
    "    print(\"  1. Ensure you have an NVIDIA GPU\")\n",
    "    print(\"  2. Install CUDA Toolkit: https://developer.nvidia.com/cuda-downloads\")\n",
    "    print(\"  3. Reinstall PyTorch with CUDA support:\")\n",
    "    print(\"     pip uninstall torch torchvision\")\n",
    "    print(\"     pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(\"\\n  For CPU-only training, set in config.yaml:\")\n",
    "    print(\"    hardware:\")\n",
    "    print(\"      device: 'cpu'\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d150b5",
   "metadata": {},
   "source": [
    "## 9. NPU Detection and Configuration\n",
    "\n",
    "Check if a Neural Processing Unit (NPU) is available on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NPU detection utilities\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "\n",
    "from src.utils.npu_utils import (\n",
    "    detect_npu_info,\n",
    "    print_npu_info,\n",
    "    check_accelerator_availability,\n",
    "    get_best_available_device\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NPU Detection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detect NPU\n",
    "npu_info = detect_npu_info()\n",
    "print_npu_info(npu_info)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Accelerator Availability\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check all accelerators\n",
    "availability = check_accelerator_availability()\n",
    "print(f\"CUDA (NVIDIA GPU): {'âœ“ Available' if availability['cuda'] else 'âœ— Not available'}\")\n",
    "print(f\"MPS (Apple Silicon): {'âœ“ Available' if availability['mps'] else 'âœ— Not available'}\")\n",
    "print(f\"NPU: {'âœ“ Available' if availability['npu'] else 'âœ— Not available'}\")\n",
    "print(f\"CPU: {'âœ“ Available' if availability['cpu'] else 'âœ— Not available'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Recommended Device\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get recommended device (prefer GPU by default)\n",
    "recommended_device = get_best_available_device(prefer_npu=False)\n",
    "print(f\"Default recommendation: {recommended_device}\")\n",
    "\n",
    "# Get recommended device with NPU preference\n",
    "recommended_with_npu = get_best_available_device(prefer_npu=True)\n",
    "print(f\"With NPU preference: {recommended_with_npu}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Configuration Tips\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if npu_info['available']:\n",
    "    npu_location = \"ðŸ”Œ External\" if npu_info.get('is_external', False) else \"ðŸ’» Internal\"\n",
    "    print(f\"âœ“ NPU Detected ({npu_location}): {npu_info['device_name']}\")\n",
    "    print(f\"  Type: {npu_info['npu_type']}\")\n",
    "    if npu_info.get('is_external', False):\n",
    "        print(f\"  Connection: {npu_info.get('connection_type', 'Unknown')}\")\n",
    "        print(\"\\n  External NPU devices (like Coral Edge TPU or Intel NCS2):\")\n",
    "        print(\"  â€¢ Best for edge inference and prototyping\")\n",
    "        print(\"  â€¢ Lower power consumption than GPUs\")\n",
    "        print(\"  â€¢ Export model to ONNX/TFLite for NPU inference\")\n",
    "    if npu_info['backend']:\n",
    "        print(f\"  Backend: {npu_info['backend']}\")\n",
    "    print(\"\\nTo use NPU in training:\")\n",
    "    print(\"  1. Set hardware.device: 'npu' in configs/default.yaml\")\n",
    "    print(\"  2. Or set hardware.prefer_npu: true for automatic selection\")\n",
    "    print(\"\\nNote: PyTorch NPU support is limited. Consider exporting to ONNX for NPU inference.\")\n",
    "else:\n",
    "    print(\"âœ— No NPU detected on this system\")\n",
    "    print(\"\\nSupported NPUs:\")\n",
    "    print(\"  - Intel AI Boost (Meteor Lake and later)\")\n",
    "    print(\"  - AMD Ryzen AI (Ryzen 7040/8040 series)\")\n",
    "    print(\"  - Apple Neural Engine (M1/M2/M3)\")\n",
    "    print(\"  - Qualcomm Hexagon NPU (Windows on ARM)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
